import sys
import os
import psutil # å¼•å…¥psutilåº“

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨sys.pathä¸­ï¼ˆé¿å…é‡å¤æ·»åŠ ï¼‰
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import subprocess
import time
import datetime
import requests
import logging
import json
import argparse
from src.data.collector_service import main as get_main
from src.trading.engine.auto_trader import main as auto_trade_main  # æ·»åŠ è‡ªåŠ¨äº¤æ˜“æ¨¡å—å¯¼å…¥
from src.core.retry_manager import retry, RetryManager
from src.core.exception_handler import setup_global_exception_handler, safe_execute
from src.core.path_manager import path_manager
import datetime
from typing import Optional
from src.ai.models.gemini_critic import main as critic_main
from src.data.critic_data_integrator import integrate_data_for_critic

# Configure logging (similar to other scripts for consistency)
# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
config_path = os.path.join(project_root, "config/config.json")
config = json.load(open(config_path, "r"))
LOG_FILE = path_manager.get_log_path("main_log")

# Prevent duplicate handlers
if not logging.getLogger("GeminiQuant").handlers:
    logging.basicConfig(
        level=logging.INFO,
        format='[ä¸»æ§è„šæœ¬][%(asctime)s] [%(levelname)s] %(message)s',
        datefmt='%H:%M:%S',
        handlers=[logging.FileHandler(LOG_FILE, mode='a', encoding='utf-8'), logging.StreamHandler()]
    )

logger = logging.getLogger("GeminiQuant")

# TODO: å°†è¿™äº›ç¡¬ç¼–ç çš„URLç§»åˆ°config.jsonä¸­ï¼Œæé«˜é…ç½®çš„çµæ´»æ€§
DATA_SERVER_URL = "http://127.0.0.1:5002"
HEALTH_ENDPOINT = f"{DATA_SERVER_URL}/health"

# å…¨å±€è°ƒè¯•æ¨¡å¼æ ‡å¿—
DEBUG_MODE = False

def wait_for_server(url: str, timeout: int = 60, retry_interval: int = 5) -> bool:
    """
    ç­‰å¾…æŒ‡å®šçš„URLè¿”å›å¥åº·çŠ¶æ€ã€‚

    é€šè¿‡è½®è¯¢å¥åº·æ£€æŸ¥ç«¯ç‚¹æ¥ç¡®è®¤æœåŠ¡æ˜¯å¦å‡†å¤‡å°±ç»ªã€‚
    è¿™åœ¨å¯åŠ¨ä¾èµ–æœåŠ¡ï¼ˆå¦‚æ•°æ®æœåŠ¡å™¨ï¼‰æ—¶éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥ç¡®ä¿ä¸»æµç¨‹åœ¨æœåŠ¡å¯ç”¨åæ‰ç»§ç»­ã€‚

    Args:
        url (str): è¦æ£€æŸ¥çš„å¥åº·ç«¯ç‚¹URLã€‚
        timeout (int): ç­‰å¾…çš„ç¸½ç§’æ•°ã€‚
        retry_interval (int): æ¯æ¬¡é‡è¯•ä¹‹é—´çš„é—´éš”ç§’æ•°ã€‚

    Returns:
        bool: å¦‚æœæœåŠ¡å™¨åœ¨è¶…æ—¶å†…è¿”å›å¥åº·çŠ¶æ€ï¼Œåˆ™ä¸ºTrueï¼Œå¦åˆ™ä¸ºFalseã€‚
    """
    logger.info(f"æ­£åœ¨ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨å¹¶å“åº”å¥åº·æ£€æŸ¥: {url}")
    start_time = time.time()
    while time.time() - start_time < timeout:
        try:
            response = requests.get(url, timeout=retry_interval) # Use retry_interval as request timeout
            if response.status_code == 200:
                data = response.json()
                status = data.get("status")
                # æ¥å— ok, starting, degraded çŠ¶æ€éƒ½ç®—æˆåŠŸ
                if status in ["ok", "starting", "degraded"]:
                    logger.info(f"æœåŠ¡å™¨å¥åº·æ£€æŸ¥é€šè¿‡ï¼ŒçŠ¶æ€: {status}")
                    return True
                else:
                    logger.warning(f"æœåŠ¡å™¨è¿”å›æœªçŸ¥çŠ¶æ€: {status}")
            else:
                logger.warning(f"æœåŠ¡å™¨è¿”å›é200çŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.ConnectionError:
            logger.info(f"æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
        except requests.exceptions.Timeout:
             logger.warning(f"å¥åº·æ£€æŸ¥è¯·æ±‚è¶…æ—¶ï¼Œç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
        except Exception as e:
            logger.error(f"å¥åº·æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

        time.sleep(retry_interval)

    logger.error("ç­‰å¾…æœåŠ¡å™¨è¶…æ—¶ï¼ŒæœåŠ¡å™¨æœªèƒ½æˆåŠŸå¯åŠ¨æˆ–å“åº”å¥åº·æ£€æŸ¥ã€‚")
    return False

# TODO: é‡æ„æ­¤å‡½æ•°ï¼Œä½¿å…¶ä¸ä¾èµ–äºå‘½ä»¤è¡Œå·¥å…·ï¼ˆå¦‚pkillï¼‰ï¼Œè€Œæ˜¯é€šè¿‡æ›´å¯é çš„è¿›ç¨‹ç®¡ç†æ–¹å¼ï¼ˆå¦‚PIDæ–‡ä»¶ï¼‰æ¥æ§åˆ¶å­è¿›ç¨‹ã€‚
def restart_data_server() -> Optional[subprocess.Popen]:
    """
    é‡å¯æ•°æ®æœåŠ¡å™¨ã€‚

    è¯¥å‡½æ•°é¦–å…ˆå°è¯•ç»ˆæ­¢ä»»ä½•ç°æœ‰çš„æ•°æ®æœåŠ¡å™¨è¿›ç¨‹ï¼Œç„¶åå¯åŠ¨ä¸€ä¸ªæ–°çš„å®ä¾‹ã€‚
    è¿™ç¡®ä¿äº†æˆ‘ä»¬æ€»æ˜¯åœ¨ä¸€ä¸ªå¹²å‡€çš„çŠ¶æ€ä¸‹å¯åŠ¨æœåŠ¡ã€‚

    Returns:
        Optional[subprocess.Popen]: å¦‚æœæˆåŠŸå¯åŠ¨ï¼Œåˆ™è¿”å›å­è¿›ç¨‹å¯¹è±¡ï¼Œå¦åˆ™è¿”å›Noneã€‚
    """
    logger.info("æ­£åœ¨é‡å¯æ•°æ®æœåŠ¡å™¨...")
    # å°è¯•æ€æ­»ç°æœ‰è¿›ç¨‹
    try:
        # Use pkill with -f to match the full command line
        subprocess.run(['pkill', '-f', 'src/infrastructure/web/data_server.py'], check=False)
        logger.info('å·²å°è¯•æ€æ­»ç°æœ‰æ•°æ®æœåŠ¡å™¨è¿›ç¨‹ã€‚')
    except Exception as e:
        logger.warning(f'æ€æ­»æ•°æ®æœåŠ¡å™¨è¿›ç¨‹å¤±è´¥æˆ–æ²¡æœ‰è¿è¡Œä¸­çš„è¿›ç¨‹: {e}')

    # å¯åŠ¨æ–°çš„æœåŠ¡å™¨è¿›ç¨‹
    # Use subprocess.Popen to run in the background
    try:
        # Assuming uv is in the PATH and the script is run from the workspace root
        server_process = subprocess.Popen(['uv', 'run', 'src/infrastructure/web/data_server.py'])
        logger.info(f"å·²å¯åŠ¨æ–°çš„æ•°æ®æœåŠ¡å™¨è¿›ç¨‹ï¼ŒPID: {server_process.pid}")
        return server_process
    except Exception as e:
        logger.critical(f"å¯åŠ¨æ•°æ®æœåŠ¡å™¨å¤±è´¥: {e}")
        return None

# TODO: æœªæ¥å¯ä»¥è€ƒè™‘å°†gemini_controlleré‡æ„ä¸ºä¸€ä¸ªç±»ï¼Œå¹¶ç›´æ¥è°ƒç”¨å…¶æ–¹æ³•ï¼Œè€Œä¸æ˜¯é€šè¿‡å­è¿›ç¨‹ã€‚
# è¿™æ ·å¯ä»¥æ›´å¥½åœ°æ§åˆ¶æ‰§è¡Œã€ä¼ é€’å‚æ•°å’Œå¤„ç†ç»“æœï¼ŒåŒæ—¶é™ä½è¿›ç¨‹é—´é€šä¿¡çš„å¼€é”€ã€‚
@retry(max_tries=3, delay_seconds=2, backoff=2, exceptions=(subprocess.CalledProcessError, Exception))
def run_gemini_api_caller(prompt_suffix: Optional[str] = None, think_mode: bool = False) -> bool:
    """
    è¿è¡Œ Gemini API è°ƒç”¨è„šæœ¬ã€‚

    Args:
        prompt_suffix (Optional[str]): è¦é™„åŠ åˆ°ä¸»æç¤ºè¯æœ«å°¾çš„é¢å¤–æ–‡æœ¬ã€‚
        think_mode (bool): æ˜¯å¦å¼€å¯æ€è€ƒæ¨¡å¼ã€‚
    
    Returns:
        bool: è„šæœ¬æ˜¯å¦æˆåŠŸè¿è¡Œã€‚
    """
    logger.info("æ­£åœ¨è¿è¡Œ Gemini API è°ƒç”¨è„šæœ¬...")
    try:
        # Assuming uv is in the PATH and the script is run from the workspace root
        # Run in foreground, wait for completion
        # TODO: æ›¿æ¢ä¸ºæ›´å¥å£®çš„Pythonå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„å‘ç°æœºåˆ¶ï¼Œè€Œä¸æ˜¯ä¾èµ–`uv run`
        command = ['uv', 'run', 'src/ai/models/gemini_controller.py']
        if prompt_suffix:
            command.extend(['--append-prompt', prompt_suffix])
        if think_mode:
            command.append('--think')
        
        result = subprocess.run(command, check=True)
        logger.info(f"Gemini API è°ƒç”¨è„šæœ¬è¿è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"Gemini API è°ƒç”¨è„šæœ¬è¿è¡Œå¤±è´¥: {e}")
        raise  # è®©é‡è¯•è£…é¥°å™¨å¤„ç†
    except Exception as e:
        logger.error(f"è¿è¡Œ Gemini API è°ƒç”¨è„šæœ¬æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        raise  # è®©é‡è¯•è£…é¥°å™¨å¤„ç†

@retry(max_tries=2, delay_seconds=2, backoff=2, exceptions=(subprocess.CalledProcessError, Exception))
def run_critic_review(current_iteration: int = 1, max_iterations: int = 3) -> bool:
    """
    è¿è¡Œè°å®˜å®¡æŸ¥æ¨¡å—ï¼Œå¯¹AIå†³ç­–è¿›è¡Œå®¡æŸ¥ã€‚
    
    Args:
        current_iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    Returns:
        bool: å®¡æŸ¥æ˜¯å¦é€šè¿‡ï¼ˆTrueè¡¨ç¤ºé€šè¿‡ï¼ŒFalseè¡¨ç¤ºéœ€è¦ä¿®æ­£ï¼‰ã€‚
    """
    logger.info(f"æ­£åœ¨è¿è¡Œè°å®˜å®¡æŸ¥æ¨¡å—ï¼ˆç¬¬{current_iteration}æ¬¡è¿­ä»£ï¼‰...")
    try:
        # è¯»å–Controllerçš„å†³ç­–ç»“æœ
        controller_answer_path = os.path.join(project_root, config["logs"]["Controller_answer_path"])
        if not os.path.exists(controller_answer_path):
            logger.error(f"Controllerå†³ç­–æ–‡ä»¶ä¸å­˜åœ¨: {controller_answer_path}")
            return False
        
        with open(controller_answer_path, "r", encoding="utf-8") as f:
            controller_decision = json.load(f)
        
        # ä½¿ç”¨æ•°æ®æ•´åˆå™¨æ•´åˆå®Œæ•´çš„è°å®˜è¾“å…¥æ•°æ®
        logger.info("æ­£åœ¨æ•´åˆè°å®˜æ‰€éœ€çš„å®Œæ•´æ•°æ®...")
        try:
            integrated_data = integrate_data_for_critic(
                decision_maker_output=controller_decision,
                current_iteration=current_iteration,
                max_iterations=max_iterations
            )
            logger.info("æ•°æ®æ•´åˆå®Œæˆ")
        except Exception as e:
            logger.error(f"æ•°æ®æ•´åˆå¤±è´¥: {e}")
            # å¦‚æœæ•°æ®æ•´åˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼
            logger.warning("å›é€€åˆ°ä¼ ç»Ÿçš„ç®€å•æ•°æ®æ ¼å¼")
            integrated_data = controller_decision
        
        # è°ƒç”¨è°å®˜æ¨¡å—è¿›è¡Œå®¡æŸ¥
        critic_result = critic_main(integrated_data)
        
        # ä¿å­˜è°å®˜å®¡æŸ¥ç»“æœ
        critic_answer_path = os.path.join(project_root, config["logs"]["Critic_answer_path"])
        
        # è§£æè°å®˜çš„è¾“å‡º
        if critic_result and len(critic_result) > 0:
            # å°†è¾“å‡ºåˆ—è¡¨åˆå¹¶ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶åå°è¯•è§£æJSON
            critic_output = "".join(critic_result)
            try:
                # å°è¯•ä»è¾“å‡ºä¸­æå–JSON
                import re
                json_match = re.search(r'\{.*\}', critic_output, re.DOTALL)
                if json_match:
                    critic_json = json.loads(json_match.group())
                    
                    # æ·»åŠ è¿­ä»£ä¿¡æ¯åˆ°å®¡æŸ¥ç»“æœ
                    critic_json["iteration_info"] = {
                        "current_iteration": current_iteration,
                        "max_iterations": max_iterations,
                        "timestamp": datetime.datetime.now().isoformat()
                    }
                    
                    # ä¿å­˜å®¡æŸ¥ç»“æœ
                    with open(critic_answer_path, "w", encoding="utf-8") as f:
                        json.dump(critic_json, f, ensure_ascii=False, indent=4)
                    
                    # æ£€æŸ¥å®¡æŸ¥çŠ¶æ€ - ä¿®æ”¹é€»è¾‘ï¼šåªè¦æ²¡æœ‰è‡´å‘½é”™è¯¯å°±é€šè¿‡
                    status = critic_json.get("status", "Needs Revision")
                    critique_report = critic_json.get("critique_report", [])
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è‡´å‘½é”™è¯¯
                    has_critical_error = False
                    for issue in critique_report:
                        severity = issue.get('severity', 'Unknown').lower()
                        description = issue.get('description', 'No description')
                        logger.info(f"å®¡æŸ¥é—®é¢˜ [{severity.upper()}]: {description}")
                        
                        # åªæœ‰Criticalçº§åˆ«çš„é”™è¯¯æ‰è¢«è®¤ä¸ºæ˜¯è‡´å‘½é”™è¯¯
                        if severity == 'critical':
                            has_critical_error = True
                            logger.error(f"å‘ç°è‡´å‘½é”™è¯¯: {description}")
                    
                    if status == "Approved" or not has_critical_error:
                        if status == "Approved":
                            logger.info(f"è°å®˜å®¡æŸ¥é€šè¿‡ï¼ˆç¬¬{current_iteration}æ¬¡è¿­ä»£ï¼‰ï¼Œå†³ç­–è·å¾—æ‰¹å‡†ã€‚")
                        else:
                            logger.info(f"è°å®˜å®¡æŸ¥é€šè¿‡ï¼ˆç¬¬{current_iteration}æ¬¡è¿­ä»£ï¼‰ï¼Œè™½æœ‰éè‡´å‘½é—®é¢˜ä½†å…è®¸æ‰§è¡Œã€‚")
                            logger.info(f"å‘ç° {len(critique_report)} ä¸ªéè‡´å‘½é—®é¢˜ï¼Œä½†ç³»ç»Ÿå°†ç»§ç»­æ‰§è¡Œã€‚")
                        return True
                    else:
                        logger.warning(f"è°å®˜å®¡æŸ¥æœªé€šè¿‡ï¼ˆç¬¬{current_iteration}æ¬¡è¿­ä»£ï¼‰ï¼Œå‘ç°è‡´å‘½é”™è¯¯ï¼Œéœ€è¦é‡æ–°å†³ç­–ã€‚")
                        return False
                else:
                    logger.error("æ— æ³•ä»è°å®˜è¾“å‡ºä¸­æå–æœ‰æ•ˆçš„JSONæ ¼å¼")
                    return False
            except json.JSONDecodeError as e:
                logger.error(f"è§£æè°å®˜è¾“å‡ºJSONå¤±è´¥: {e}")
                logger.error(f"åŸå§‹è¾“å‡º: {critic_output}")
                return False
        else:
            logger.error("è°å®˜æ¨¡å—è¿”å›ç©ºç»“æœ")
            return False
            
    except Exception as e:
        logger.error(f"è¿è¡Œè°å®˜å®¡æŸ¥æ¨¡å—æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        raise  # è®©é‡è¯•è£…é¥°å™¨å¤„ç†

def run_auto_trader(dry_run: bool = False) -> bool:
    """
    è¿è¡Œè‡ªåŠ¨äº¤æ˜“ç³»ç»Ÿã€‚

    Args:
        dry_run (bool): æ˜¯å¦ä¸ºæ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ã€‚
    """
    logger.info("æ­£åœ¨è¿è¡Œè‡ªåŠ¨äº¤æ˜“ç³»ç»Ÿ...")
    if dry_run:
        logger.info("æ¨¡å¼: Dry Run (æ¨¡æ‹Ÿè¿è¡Œ)")
    try:
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¿®æ”¹ auto_trader.py çš„ main å‡½æ•°æ¥æ¥å— dry_run å‚æ•°
        if auto_trade_main(dry_run=dry_run):
            logger.info("è‡ªåŠ¨äº¤æ˜“ç³»ç»Ÿè¿è¡Œå®Œæˆ")
            return True
    except Exception as e:
        logger.error(f"æ‰§è¡Œäº¤æ˜“æ—¶å‘ç”Ÿé¡¶å±‚å¼‚å¸¸: {e}", exc_info=True)
        return False

def parse_arguments() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚
    
    Returns:
        argparse.Namespace: è§£æåçš„å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡ã€‚
    """
    parser = argparse.ArgumentParser(description='å¤ªç†µé‡åŒ–äº¤æ˜“ç³»ç»Ÿ - ä¸»æ§åˆ¶å™¨', formatter_class=argparse.RawTextHelpFormatter)

    # è°ƒè¯•ä¸æ¨¡å¼æ§åˆ¶
    group_mode = parser.add_argument_group('è°ƒè¯•ä¸æ¨¡å¼æ§åˆ¶')
    group_mode.add_argument('--debug', '-d', action='store_true', 
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡å®Œæ•´äº¤æ˜“æµç¨‹åé€€å‡º')
    group_mode.add_argument('--debug-loop', action='store_true',
                       help='å¯ç”¨è°ƒè¯•å¾ªç¯æ¨¡å¼ï¼šè¿ç»­æ‰§è¡Œäº¤æ˜“æµç¨‹ï¼Œæ— æ—¶é—´ç­‰å¾…')
    group_mode.add_argument('--dry-run', action='store_true',
                       help='æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼šæ‰§è¡Œæ‰€æœ‰æ­¥éª¤ï¼Œä½†ä¸ä¼šå®é™…ä¸‹å•äº¤æ˜“')
    group_mode.add_argument('--think', action='store_true',
                       help='æ€è€ƒæ‘˜è¦æ¨¡å¼ï¼šåœ¨AIå†³ç­–æ—¶ï¼Œå®æ—¶æ‰“å°æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹å’Œä»£ç è¾“å‡º')

    # é…ç½®ä¸è·¯å¾„
    group_config = parser.add_argument_group('é…ç½®ä¸è·¯å¾„')
    group_config.add_argument('--config', type=str, default=None,
                        help='æŒ‡å®šè‡ªå®šä¹‰çš„config.jsoné…ç½®æ–‡ä»¶è·¯å¾„')
    group_config.add_argument('--log-level', type=str, default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        help='è®¾ç½®æ—¥å¿—è®°å½•çº§åˆ« (é»˜è®¤ä¸º: INFO)')

    # æœåŠ¡å™¨ä¸æœåŠ¡
    group_server = parser.add_argument_group('æœåŠ¡å™¨ä¸æœåŠ¡')
    group_server.add_argument('--skip-server', action='store_true',
                       help='è·³è¿‡æ•°æ®æœåŠ¡å™¨å¯åŠ¨ï¼ˆå‡è®¾æœåŠ¡å™¨å·²è¿è¡Œï¼‰')
    
    # å¸®åŠ©
    group_help = parser.add_argument_group('å¸®åŠ©')
    group_help.add_argument('--help-debug', action='store_true',
                       help='æ˜¾ç¤ºè°ƒè¯•æ¨¡å¼è¯¦ç»†è¯´æ˜')
    
    # åœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œsys.argvå¯èƒ½åŒ…å«pytestçš„å‚æ•°ï¼Œè¿™ä¼šå¯¼è‡´è§£æé”™è¯¯ã€‚
    # TODO: è€ƒè™‘ä½¿ç”¨æ›´çµæ´»çš„é…ç½®æ–¹å¼ï¼ˆå¦‚ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ï¼‰æ¥ä»£æ›¿å‘½ä»¤è¡Œå‚æ•°ï¼Œä»¥ç®€åŒ–æµ‹è¯•ã€‚
    known_args, _ = parser.parse_known_args()
    return known_args

def show_debug_help():
    """æ˜¾ç¤ºè°ƒè¯•æ¨¡å¼å¸®åŠ©ä¿¡æ¯"""
    help_text = """
ğŸ”§ å¤ªç†µé‡åŒ–äº¤æ˜“ç³»ç»Ÿ - è°ƒè¯•æ¨¡å¼è¯´æ˜

è°ƒè¯•æ¨¡å¼é€‰é¡¹ï¼š
  --debug, -d          : å•æ¬¡è°ƒè¯•æ¨¡å¼
                        - ç«‹å³å¯åŠ¨æ•°æ®æœåŠ¡å™¨
                        - æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„äº¤æ˜“æµç¨‹
                        - æ‰§è¡Œå®Œæˆåé€€å‡ºç¨‹åº
                        
  --debug-loop         : å¾ªç¯è°ƒè¯•æ¨¡å¼  
                        - è¿ç»­æ‰§è¡Œäº¤æ˜“æµç¨‹
                        - æ— 30åˆ†é’Ÿæ—¶é—´é—´éš”ç­‰å¾…
                        - é€‚åˆå¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•
                        
  --skip-server        : è·³è¿‡æœåŠ¡å™¨å¯åŠ¨
                        - å‡è®¾æ•°æ®æœåŠ¡å™¨å·²åœ¨è¿è¡Œ
                        - ç›´æ¥æ‰§è¡Œäº¤æ˜“æµç¨‹
                        - é€‚åˆæœåŠ¡å™¨å·²å¯åŠ¨çš„æƒ…å†µ

ä½¿ç”¨ç¤ºä¾‹ï¼š
  uv run python3 src/main.py --debug           # å•æ¬¡è°ƒè¯•è¿è¡Œ
  uv run python3 src/main.py --debug-loop     # å¾ªç¯è°ƒè¯•è¿è¡Œ
  uv run python3 src/main.py --skip-server    # è·³è¿‡æœåŠ¡å™¨å¯åŠ¨
  uv run python3 src/main.py                  # æ­£å¸¸ç”Ÿäº§æ¨¡å¼

æ³¨æ„ï¼šè°ƒè¯•æ¨¡å¼ä¼šè·³è¿‡æ—¶é—´æ£€æŸ¥ï¼Œç«‹å³æ‰§è¡Œäº¤æ˜“åˆ†æå’Œå†³ç­–ã€‚
"""
    print(help_text)

# å…¨å±€å˜é‡ï¼šç´¯ç§¯è°å®˜åé¦ˆ
cumulative_critic_feedback = []

def add_critic_feedback_to_cumulative(attempt_number: int) -> bool:
    """
    å°†å½“å‰è°å®˜åé¦ˆæ·»åŠ åˆ°ç´¯ç§¯åé¦ˆåˆ—è¡¨ä¸­ã€‚
    
    Args:
        attempt_number (int): å½“å‰å°è¯•æ¬¡æ•°
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸæ·»åŠ åé¦ˆ
    """
    global cumulative_critic_feedback
    
    try:
        critic_answer_path = os.path.join(project_root, config["logs"]["Critic_answer_path"])
        if not os.path.exists(critic_answer_path):
            logger.warning(f"ç¬¬{attempt_number}æ¬¡ï¼šæœªæ‰¾åˆ°è°å®˜å®¡æŸ¥ç»“æœæ–‡ä»¶")
            return False
        
        with open(critic_answer_path, "r", encoding="utf-8") as f:
            critic_result = json.load(f)
        
        critique_report = critic_result.get("critique_report", [])
        if not critique_report:
            logger.warning(f"ç¬¬{attempt_number}æ¬¡ï¼šè°å®˜å®¡æŸ¥ç»“æœä¸ºç©º")
            return False
        
        # æ·»åŠ å½“å‰åé¦ˆåˆ°ç´¯ç§¯åˆ—è¡¨
        feedback_entry = {
            "attempt": attempt_number,
            "timestamp": critic_result.get("timestamp", "æœªçŸ¥æ—¶é—´"),
            "status": critic_result.get("status", "Needs Revision"),
            "critique_report": critique_report
        }
        
        cumulative_critic_feedback.append(feedback_entry)
        logger.info(f"å·²å°†ç¬¬{attempt_number}æ¬¡è°å®˜åé¦ˆæ·»åŠ åˆ°ç´¯ç§¯åé¦ˆä¸­ï¼Œå½“å‰ç´¯ç§¯{len(cumulative_critic_feedback)}è½®åé¦ˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"æ·»åŠ ç¬¬{attempt_number}æ¬¡è°å®˜åé¦ˆæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return False

def get_cumulative_critic_feedback_as_prompt() -> str:
    """
    ä»ç´¯ç§¯çš„è°å®˜å®¡æŸ¥ç»“æœä¸­ç”ŸæˆåŒ…å«æ‰€æœ‰å†å²åé¦ˆçš„æç¤ºè¯ã€‚
    
    Returns:
        str: åŸºäºæ‰€æœ‰å†å²è°å®˜åé¦ˆçš„æç¤ºè¯
    """
    global cumulative_critic_feedback
    
    if not cumulative_critic_feedback:
        logger.warning("æ²¡æœ‰ç´¯ç§¯çš„è°å®˜åé¦ˆï¼Œä½¿ç”¨é€šç”¨é‡è¯•æç¤º")
        return "ä½ çš„ä¸Šä¸€ä¸ªæŒ‡ä»¤åœ¨æ‰§è¡Œæ—¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æŒ‡ä»¤çš„JSONæ ¼å¼ã€ä»·æ ¼ã€æ­¢ç›ˆæ­¢æŸç­‰å‚æ•°çš„æ­£ç¡®æ€§å’Œé€»è¾‘åˆç†æ€§ï¼Œç„¶åé‡æ–°ç”ŸæˆæŒ‡ä»¤ã€‚"
    
    try:
        # æ„å»ºåŒ…å«æ‰€æœ‰å†å²åé¦ˆçš„æç¤ºè¯
        feedback_parts = [f"æ ¹æ®è¿™ä¸€è½®äº¤æ˜“æµç¨‹ä¸­çš„{len(cumulative_critic_feedback)}æ¬¡è°å®˜å®¡æŸ¥ç»“æœï¼Œä½ éœ€è¦ä¿®æ­£ä»¥ä¸‹ç´¯ç§¯å‘ç°çš„é—®é¢˜ï¼š\n"]
        
        issue_counter = 1
        for round_idx, feedback_entry in enumerate(cumulative_critic_feedback, 1):
            attempt = feedback_entry.get("attempt", round_idx)
            critique_report = feedback_entry.get("critique_report", [])
            
            if critique_report:
                feedback_parts.append(f"=== ç¬¬{attempt}æ¬¡å†³ç­– - è°å®˜å®¡æŸ¥å‘ç°çš„é—®é¢˜ ===")
                
                for issue in critique_report:
                    severity = issue.get('severity', 'Unknown')
                    description = issue.get('description', 'æœªæä¾›æè¿°')
                    suggested_correction = issue.get('suggested_correction', 'è¯·é‡æ–°è¯„ä¼°')
                    
                    feedback_parts.append(f"{issue_counter}. [{severity}] {description}")
                    feedback_parts.append(f"   ä¿®æ­£å»ºè®®ï¼š{suggested_correction}")
                    issue_counter += 1
                
                feedback_parts.append("")  # ç©ºè¡Œåˆ†éš”
        
        feedback_parts.append("=== é‡è¦æé†’ ===")
        feedback_parts.append("ä»¥ä¸Šæ˜¯è¿™ä¸€è½®äº¤æ˜“æµç¨‹ä¸­æ‰€æœ‰è°å®˜å®¡æŸ¥å‘ç°çš„é—®é¢˜ã€‚è¯·ä»”ç»†é˜…è¯»æ‰€æœ‰å†å²åé¦ˆï¼Œç¡®ä¿ï¼š")
        feedback_parts.append("1. ä¸è¦é‡å¤ä¹‹å‰å·²ç»å‘ç°å’ŒæŒ‡å‡ºçš„é”™è¯¯")
        feedback_parts.append("2. ç»¼åˆè€ƒè™‘æ‰€æœ‰åé¦ˆï¼Œè¿›è¡Œå…¨é¢çš„ä¿®æ­£")
        feedback_parts.append("3. ç‰¹åˆ«æ³¨æ„Criticalçº§åˆ«çš„é—®é¢˜ï¼Œå¿…é¡»å®Œå…¨è§£å†³")
        feedback_parts.append("4. å­¦ä¹ ä¹‹å‰çš„é”™è¯¯æ¨¡å¼ï¼Œé¿å…ç±»ä¼¼é—®é¢˜å†æ¬¡å‡ºç°")
        feedback_parts.append("\nè¯·åŸºäºä»¥ä¸Šå®Œæ•´çš„å†å²åé¦ˆï¼Œé‡æ–°åˆ†æå¸‚åœºæ•°æ®ï¼Œä¿®æ­£æ‰€æœ‰å‘ç°çš„é—®é¢˜ï¼Œå¹¶ç”Ÿæˆæ–°çš„äº¤æ˜“å†³ç­–ã€‚")
        
        return "\n".join(feedback_parts)
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆç´¯ç§¯è°å®˜åé¦ˆæç¤ºè¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return "ä½ çš„ä¸Šä¸€ä¸ªå†³ç­–æœªé€šè¿‡è°å®˜å®¡æŸ¥ï¼Œè¯·é‡æ–°åˆ†æå¸‚åœºæ•°æ®å¹¶ç”Ÿæˆæ›´åŠ åˆç†çš„äº¤æ˜“å†³ç­–ã€‚"

def reset_cumulative_critic_feedback():
    """é‡ç½®ç´¯ç§¯è°å®˜åé¦ˆï¼Œç”¨äºæ–°çš„äº¤æ˜“æµç¨‹å¼€å§‹æ—¶ã€‚"""
    global cumulative_critic_feedback
    cumulative_critic_feedback = []
    logger.info("å·²é‡ç½®ç´¯ç§¯è°å®˜åé¦ˆï¼Œå¼€å§‹æ–°çš„äº¤æ˜“æµç¨‹")

def run_full_trade_flow(args: argparse.Namespace) -> bool:
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„äº¤æ˜“æµç¨‹ï¼Œä»æ•°æ®æ”¶é›†åˆ°äº¤æ˜“æ‰§è¡Œã€‚
    
    ä¼˜åŒ–è®¾è®¡ï¼š
    - æ•°æ®æ”¶é›†åªæ‰§è¡Œä¸€æ¬¡ï¼Œç¡®ä¿æ‰€æœ‰å†³ç­–å°è¯•åŸºäºç›¸åŒçš„å¸‚åœºæ•°æ®
    - è°å®˜å®¡æŸ¥å¤±è´¥åç›´æ¥é‡æ–°å†³ç­–ï¼Œä¸é‡æ–°æ”¶é›†æ•°æ®
    - äº¤æ˜“æ‰§è¡Œå¤±è´¥åä¹Ÿç›´æ¥é‡æ–°å†³ç­–ï¼Œä¸é‡æ–°æ”¶é›†æ•°æ®
    
    Args:
        args (argparse.Namespace): è§£æåçš„å‘½ä»¤è¡Œå‚æ•°ã€‚

    Returns:
        bool: äº¤æ˜“æµç¨‹æ˜¯å¦æˆåŠŸæ‰§è¡Œã€‚
    """
    try:
        # 0. é‡ç½®ç´¯ç§¯è°å®˜åé¦ˆï¼Œå¼€å§‹æ–°çš„äº¤æ˜“æµç¨‹
        reset_cumulative_critic_feedback()
        
        # 1. è¿è¡Œæ•°æ®æ”¶é›†ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼Œç¡®ä¿æ‰€æœ‰åç»­å†³ç­–åŸºäºç›¸åŒæ•°æ®ï¼‰
        logger.info("æ­£åœ¨è¿è¡Œæ•°æ®æ”¶é›†æ¨¡å—...")
        get_main()
        logger.info("æ•°æ®æ”¶é›†æ¨¡å—è¿è¡Œå®Œæˆã€‚æ‰€æœ‰åç»­å†³ç­–å°†åŸºäºè¿™ä»½æ•°æ®è¿›è¡Œã€‚")

        # 2. åŸºäºæ”¶é›†çš„æ•°æ®è¿›è¡Œå†³ç­–-å®¡æŸ¥-æ‰§è¡Œå¾ªç¯
        success = False
        # äº¤æ˜“æ‰§è¡Œå¤±è´¥åé‡æ–°å†³ç­–çš„é€šç”¨æç¤ºè¯
        EXECUTION_FAILURE_PROMPT = "ä½ çš„ä¸Šä¸€ä¸ªæŒ‡ä»¤åœ¨äº¤æ˜“æ‰§è¡Œæ—¶å¤±è´¥ï¼Œè¯·æ£€æŸ¥æŒ‡ä»¤çš„JSONæ ¼å¼ã€ä»·æ ¼ã€æ­¢ç›ˆæ­¢æŸç­‰å‚æ•°çš„æ­£ç¡®æ€§å’Œé€»è¾‘åˆç†æ€§ï¼Œç„¶åé‡æ–°ç”ŸæˆæŒ‡ä»¤ã€‚"
        
        # è·Ÿè¸ªä¸Šæ¬¡å¤±è´¥çš„åŸå› ï¼š'critic' è¡¨ç¤ºè°å®˜å®¡æŸ¥å¤±è´¥ï¼Œ'execution' è¡¨ç¤ºäº¤æ˜“æ‰§è¡Œå¤±è´¥
        last_failure_reason = None

        for attempt in range(10):
            if attempt == 0:
                logger.info(f"å¼€å§‹ç¬¬ {attempt + 1} æ¬¡å†³ç­–å°è¯•ï¼ˆåŸºäºå·²æ”¶é›†çš„å¸‚åœºæ•°æ®ï¼‰...")
            else:
                logger.info(f"å¼€å§‹ç¬¬ {attempt + 1} æ¬¡é‡æ–°å†³ç­–ï¼ˆä¸é‡æ–°æ”¶é›†æ•°æ®ï¼‰...")
            
            # æ ¹æ®ä¸Šæ¬¡å¤±è´¥åŸå› ç¡®å®šæç¤ºè¯
            prompt_to_use = None
            if attempt > 0:
                if last_failure_reason == 'critic':
                    # ä½¿ç”¨ç´¯ç§¯çš„è°å®˜åé¦ˆ
                    prompt_to_use = get_cumulative_critic_feedback_as_prompt()
                    logger.info(f"æœ¬æ¬¡ä¸ºè°å®˜å®¡æŸ¥å¤±è´¥åé‡æ–°å†³ç­–ï¼Œä½¿ç”¨ç´¯ç§¯è°å®˜åé¦ˆä½œä¸ºæç¤ºè¯")
                elif last_failure_reason == 'execution':
                    # ä½¿ç”¨æ‰§è¡Œå¤±è´¥çš„é€šç”¨æç¤ºè¯
                    prompt_to_use = EXECUTION_FAILURE_PROMPT
                    logger.info(f"æœ¬æ¬¡ä¸ºäº¤æ˜“æ‰§è¡Œå¤±è´¥åé‡æ–°å†³ç­–ï¼Œä½¿ç”¨æ‰§è¡Œå¤±è´¥æç¤ºè¯")
                else:
                    # å…œåº•æƒ…å†µ
                    prompt_to_use = EXECUTION_FAILURE_PROMPT
                    logger.info(f"æœ¬æ¬¡ä¸ºé‡è¯•ï¼Œä½¿ç”¨é€šç”¨å¤±è´¥æç¤ºè¯")
                
                logger.info(f"é™„åŠ æç¤ºè¯: '{prompt_to_use[:200]}...'")

            try:
                # è°ƒç”¨AIå†³ç­–ï¼ˆåŸºäºå·²æ”¶é›†çš„æ•°æ®ï¼‰
                run_gemini_api_caller(prompt_suffix=prompt_to_use, think_mode=args.think)
                
                # è°å®˜å®¡æŸ¥å†³ç­–
                critic_passed = run_critic_review(current_iteration=attempt + 1, max_iterations=10)
                if not critic_passed:
                    # å°†å½“å‰è°å®˜åé¦ˆæ·»åŠ åˆ°ç´¯ç§¯åé¦ˆä¸­
                    add_critic_feedback_to_cumulative(attempt + 1)
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡è°å®˜å®¡æŸ¥æœªé€šè¿‡ï¼Œå°†ç›´æ¥é‡æ–°å†³ç­–ï¼ˆä¸é‡æ–°æ”¶é›†æ•°æ®ï¼‰...")
                    last_failure_reason = 'critic'
                    continue
                
                # æ‰§è¡Œäº¤æ˜“
                if run_auto_trader(dry_run=args.dry_run):
                    logger.info(f"ç¬¬ {attempt + 1} æ¬¡äº¤æ˜“å°è¯•æˆåŠŸã€‚")
                    success = True
                    break
                else:
                    logger.warning(f"ç¬¬ {attempt + 1} æ¬¡è‡ªåŠ¨äº¤æ˜“æ‰§è¡Œå¤±è´¥æˆ–è¿”å›äº†å¦å®šä¿¡å·ï¼Œå°†ç›´æ¥é‡æ–°å†³ç­–ï¼ˆä¸é‡æ–°æ”¶é›†æ•°æ®ï¼‰...")
                    last_failure_reason = 'execution'
            except Exception as e:
                logger.error(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
                last_failure_reason = 'execution'
        
        if success:
            logger.info("äº¤æ˜“æµç¨‹æ‰§è¡ŒæˆåŠŸ")
        else:
            logger.error("æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œäº¤æ˜“æµç¨‹æ‰§è¡Œå¤±è´¥")
            
        return success
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œäº¤æ˜“æµç¨‹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        logger.exception(e)
        return False

def run_debug_loop(args: argparse.Namespace):
    """
    åœ¨è°ƒè¯•å¾ªç¯æ¨¡å¼ä¸‹è¿è¡Œï¼Œè¿ç»­æ‰§è¡Œäº¤æ˜“æµç¨‹ã€‚
    
    Args:
        args (argparse.Namespace): è§£æåçš„å‘½ä»¤è¡Œå‚æ•°ã€‚
    """
    run_count = 0
    while True:
        run_count += 1
        logger.info(f"--- å¼€å§‹ç¬¬ {run_count} è½®è°ƒè¯•å¾ªç¯ ---")
        try:
            run_full_trade_flow(args)
            logger.info(f"--- ç¬¬ {run_count} è½®è°ƒè¯•å¾ªç¯å®Œæˆ ---")
        except Exception as e:
            logger.error(f"åœ¨ç¬¬ {run_count} è½®è°ƒè¯•å¾ªç¯ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            logger.info("ç³»ç»Ÿå°†åœ¨60ç§’åå°è¯•é‡å¯ä¸»å¾ªç¯...")
            time.sleep(60)

def kill_existing_processes():
    """æŸ¥æ‰¾å¹¶ç»ˆæ­¢ä»»ä½•å·²åœ¨è¿è¡Œçš„ main_controller.py è¿›ç¨‹ï¼Œé˜²æ­¢é‡å¤è¿è¡Œã€‚"""
    current_pid = os.getpid()
    script_name = os.path.basename(__file__)
    
    killed_count = 0
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            # æ£€æŸ¥è¿›ç¨‹å‘½ä»¤è¡Œä¸­æ˜¯å¦åŒ…å«è„šæœ¬å
            if script_name in proc.info['cmdline'] and proc.info['pid'] != current_pid:
                logger.warning(f"å‘ç°å·²åœ¨è¿è¡Œçš„æ—§è¿›ç¨‹: PID={proc.info['pid']}, å‘½ä»¤è¡Œ: {' '.join(proc.info['cmdline'])}")
                p = psutil.Process(proc.info['pid'])
                p.terminate()  # å‘é€ç»ˆæ­¢ä¿¡å·
                p.wait(timeout=3) # ç­‰å¾…è¿›ç¨‹ç»ˆæ­¢
                logger.info(f"å·²æˆåŠŸç»ˆæ­¢æ—§è¿›ç¨‹ (PID: {proc.info['pid']})")
                killed_count += 1
        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.TimeoutExpired) as e:
            logger.error(f"ç»ˆæ­¢æ—§è¿›ç¨‹ (PID: {proc.info.get('pid')}) æ—¶å‡ºé”™: {e}")
        except Exception as e:
            # æ•è·å…¶ä»–å¯èƒ½çš„å¼‚å¸¸ï¼Œä¾‹å¦‚proc.info['cmdline']ä¸ºç©ºçš„æƒ…å†µ
            continue
            
    if killed_count > 0:
        logger.info(f"å…±ç»ˆæ­¢äº† {killed_count} ä¸ªæ—§çš„è¿›ç¨‹å®ä¾‹ã€‚")

def main():
    """
    ç³»ç»Ÿä¸»å…¥å£å‡½æ•°ã€‚
    
    è´Ÿè´£åˆå§‹åŒ–ã€å‚æ•°è§£æã€æ¨¡å¼é€‰æ‹©å’Œå¯åŠ¨ç›¸åº”çš„æ‰§è¡Œå¾ªç¯ã€‚
    """
    # åœ¨æœ€å¼€å§‹å°±æ‰§è¡ŒæŸ¥æ€é€»è¾‘
    kill_existing_processes()

    global DEBUG_MODE
    global config
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # 1. æ ¹æ®å‚æ•°é‡æ–°åŠ è½½é…ç½®å’Œè®¾ç½®æ—¥å¿—çº§åˆ«
    if args.config:
        logger.info(f"åŠ è½½æŒ‡å®šé…ç½®æ–‡ä»¶: {args.config}")
        with open(args.config, "r", encoding="utf-8") as f:
            config = json.load(f)
    
    log_level_map = {
        'DEBUG': logging.DEBUG,
        'INFO': logging.INFO,
        'WARNING': logging.WARNING,
        'ERROR': logging.ERROR,
        'CRITICAL': logging.CRITICAL
    }
    effective_log_level = log_level_map.get(args.log_level.upper(), logging.INFO)
    logging.getLogger("GeminiQuant").setLevel(effective_log_level)
    logger.info(f"æ—¥å¿—çº§åˆ«å·²è®¾ç½®ä¸º: {args.log_level}")

    # æ˜¾ç¤ºè°ƒè¯•å¸®åŠ©
    if args.help_debug:
        show_debug_help()
        return
    
    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    DEBUG_MODE = args.debug or args.debug_loop
    
    # è®¾ç½®å…¨å±€å¼‚å¸¸å¤„ç†å™¨
    setup_global_exception_handler()
    
    logger.info("=== å¤ªç†µé‡åŒ–äº¤æ˜“ç³»ç»Ÿå¯åŠ¨ ===")
    if DEBUG_MODE:
        mode_name = "å•æ¬¡è°ƒè¯•æ¨¡å¼" if args.debug else "å¾ªç¯è°ƒè¯•æ¨¡å¼"
        logger.info(f"ğŸ”§ è¿è¡Œæ¨¡å¼: {mode_name}")
    else:
        logger.info("ğŸš€ è¿è¡Œæ¨¡å¼: ç”Ÿäº§æ¨¡å¼")
    
    # 1. å¯åŠ¨æ•°æ®æœåŠ¡å™¨ï¼ˆé™¤éè·³è¿‡ï¼‰
    if not args.skip_server:
        server_process = restart_data_server()
        if server_process is None:
            logger.critical("æ•°æ®æœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼Œä¸»æ§è„šæœ¬é€€å‡ºã€‚")
            exit(1)

        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨å®Œæˆå¹¶è‡ªæ£€é€šè¿‡
        time.sleep(15)  # Initial wait
        if not wait_for_server(HEALTH_ENDPOINT, timeout=120, retry_interval=10):
            logger.critical("æ•°æ®æœåŠ¡å™¨æœªèƒ½åœ¨è§„å®šæ—¶é—´å†…å¯åŠ¨å¹¶è‡ªæ£€é€šè¿‡ï¼Œä¸»æ§è„šæœ¬é€€å‡ºã€‚")
            exit(1)
    else:
        logger.info("è·³è¿‡æ•°æ®æœåŠ¡å™¨å¯åŠ¨ï¼Œå‡è®¾æœåŠ¡å™¨å·²è¿è¡Œ")

    # 4. æ ¹æ®æ¨¡å¼æ‰§è¡Œ
    if args.debug:
        logger.info("å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå°†æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„äº¤æ˜“æµç¨‹ã€‚")
        success = run_full_trade_flow(args)
        logger.info(f"è°ƒè¯•æ¨¡å¼æ‰§è¡Œå®Œæˆï¼Œç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    elif args.debug_loop:
        logger.info("å¯ç”¨è°ƒè¯•å¾ªç¯æ¨¡å¼ï¼Œå°†è¿ç»­æ‰§è¡Œäº¤æ˜“æµç¨‹ã€‚")
        run_debug_loop(args)
    else:
        logger.info("å¯ç”¨ç”Ÿäº§æ¨¡å¼ï¼Œå°†åœ¨æ¯30åˆ†é’Ÿçš„æ•´ç‚¹æ—¶æ‰§è¡Œï¼ˆå¦‚9:00ã€9:30ã€10:00ç­‰ï¼‰ã€‚")
        while True:
            try:
                # è·å–å½“å‰æ—¶é—´
                now = datetime.datetime.now()
                current_minute = now.minute
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯30åˆ†é’Ÿçš„æ•´ç‚¹ï¼ˆåˆ†é’Ÿæ•°èƒ½è¢«30æ•´é™¤ï¼‰
                if current_minute % 30 == 0:
                    logger.info(f"å½“å‰æ—¶é—´ {now.strftime('%H:%M')} ç¬¦åˆæ‰§è¡Œæ¡ä»¶ï¼Œå¼€å§‹æ‰§è¡Œäº¤æ˜“æµç¨‹...")
                    run_full_trade_flow(args)
                    logger.info("äº¤æ˜“æµç¨‹æ‰§è¡Œå®Œæˆã€‚")
                    
                    # ç­‰å¾…åˆ°ä¸‹ä¸€åˆ†é’Ÿï¼Œé¿å…åœ¨åŒä¸€åˆ†é’Ÿå†…é‡å¤æ‰§è¡Œ
                    time.sleep(60)
                else:
                    # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ª30åˆ†é’Ÿæ•´ç‚¹çš„ç­‰å¾…æ—¶é—´
                    if current_minute < 30:
                        next_target_minute = 30
                    else:
                        next_target_minute = 60
                    
                    wait_minutes = next_target_minute - current_minute
                    wait_seconds = wait_minutes * 60 - now.second
                    
                    next_time = now.replace(minute=next_target_minute % 60, second=0, microsecond=0)
                    if next_target_minute == 60:
                        next_time = next_time.replace(hour=(now.hour + 1) % 24)
                    
                    logger.info(f"å½“å‰æ—¶é—´ {now.strftime('%H:%M:%S')}ï¼Œä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_time.strftime('%H:%M:%S')}ï¼Œç­‰å¾… {wait_seconds} ç§’...")
                    time.sleep(wait_seconds)
                    
            except KeyboardInterrupt:
                logger.info("æ£€æµ‹åˆ°æ‰‹åŠ¨ä¸­æ–­ï¼Œæ­£åœ¨æ­£å¸¸å…³é—­ç³»ç»Ÿ...")
                break
            except Exception as e:
                logger.error(f"åœ¨ä¸»å¾ªç¯ä¸­å‘ç”Ÿæœªæ•è·çš„é”™è¯¯: {e}", exc_info=True)
                logger.info("ç³»ç»Ÿå°†åœ¨60ç§’åå°è¯•é‡å¯ä¸»å¾ªç¯...")
                time.sleep(60)

if __name__ == "__main__":
    main()